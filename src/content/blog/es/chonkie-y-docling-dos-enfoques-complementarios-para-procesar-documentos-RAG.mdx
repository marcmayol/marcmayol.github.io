---
title: 'Chonkie y Docling: dos enfoques complementarios para procesar documentos en pipelines RAG'
description: 'Comparativa entre Chonkie y Docling, dos herramientas clave para procesar documentos en pipelines RAG. Descubre sus diferencias, ventajas y c√≥mo combinarlas para obtener mejores resultados en IA.'
pubDate: 'Oct 17, 2025'
heroImage: '/doclingvschonkiepng.png'
customURL: '/blog/en/chonkie-and-docling-two-complementary-approaches-to-document-processing-RAG/'
---

En el mundo del orden y la recuperaci√≥n inteligente de textos (por ejemplo, en arquitecturas **RAG** ‚Äî *retrieval-augmented generation*), uno de los retos fundamentales es preparar los documentos para que sean ‚Äúdigeribles‚Äù por los componentes de recuperaci√≥n y generaci√≥n. Aqu√≠ entra en juego el **chunking** ‚Äî es decir, fragmentar el texto en pedazos coherentes ‚Äî, pero tambi√©n la correcta interpretaci√≥n del documento en s√≠ (estructura, tablas, dise√±o, etc.).

Dos herramientas recientes destacan por sus enfoques distintos, pero potencialmente complementarios:

* **Chonkie**: especializada en fragmentaci√≥n ligera, modular y eficiente del texto para pipelines de IA.
* **Docling**: enfocada en la ingesti√≥n y representaci√≥n rica de documentos de m√∫ltiples formatos, con conciencia de estructura, layout, tablas, OCR, etc.

A continuaci√≥n exploramos c√≥mo funcionan, sus diferencias clave y c√≥mo combinarlas para construir pipelines RAG m√°s potentes.


<br/>
## Chonkie: el hipop√≥tamo ligero que trocea tus textos con elegancia

> *‚ÄúCHONK your texts with Chonkie‚Äù* es el lema simp√°tico de esta librer√≠a, que pretende ser ‚Äúno-nonsense‚Äù (sin florituras in√∫tiles) y ultra-ligera.
> üëâ <a href="https://github.com/chonkie-inc/chonkie" title="Repositorio oficial chonlie">https://github.com/chonkie-inc/chonkie</a>

### ¬øPor qu√© existe Chonkie?

En el desarrollo de sistemas RAG o motores de b√∫squeda sem√°ntica, suele repetirse un mismo problema: la fragmentaci√≥n del texto.
Dividir documentos grandes en trozos coherentes sin perder contexto es un equilibrio delicado.

Muchas librer√≠as ofrecen soluciones, pero a menudo incluyen dependencias innecesarias o un tama√±o excesivo. Chonkie se centra solo en lo esencial: **chunking eficiente**, **refinamiento** y **exportaci√≥n modular**.

En sus benchmarks propios, indican que su instalaci√≥n base ocupa unos **15 MB**, frente a los **80‚Äì170 MB** de librer√≠as alternativas, y que su chunking por tokens puede ser hasta **33 √ó m√°s r√°pido**.


<br/>
### Caracter√≠sticas principales

* **Chunkers m√∫ltiples**:

* `TokenChunker`: divide por tokens.
* `SentenceChunker`: divide por oraciones.
* `RecursiveChunker`: divisi√≥n jer√°rquica.
* `SemanticChunker`: basado en similitud sem√°ntica (embeddings).
* Otros: `LateChunker`, `CodeChunker`, `SlumberChunker`, etc.

* **Pipeline modular y refinamiento**:
Encadena etapas: chunking ‚Üí refinado (solapamientos, embeddings) ‚Üí exportaci√≥n.

* **Integraciones**:
Compatibilidad con bases vectoriales como **Chroma**, **Qdrant**, **Pinecone**, **pgvector**, entre otras.

* **Soporte multiling√ºe**:
Soporta m√°s de **50 idiomas**, lo que facilita trabajar con contenidos globales.

* **Chonkie Cloud**:
Adem√°s de la versi√≥n local, dispone de un servicio en la nube para delegar la fragmentaci√≥n.


<br/>
### Ejemplo b√°sico

```python
from chonkie import TokenChunker

chunker = TokenChunker()
chunks = chunker("Este es un texto de ejemplo que quiero fragmentar en pedazos √∫tiles.")
for c in chunks:
    print(c.text, c.token_count)
```

Ejemplo de pipeline m√°s complejo:

```python
    from chonkie import Pipeline

    pipe = (
        Pipeline()
        .chunk_with("recursive", tokenizer="gpt2", chunk_size=2048, recipe="markdown")
        .chunk_with("semantic", chunk_size=512)
        .refine_with("overlap", context_size=128)
        .refine_with("embeddings", embedding_model="sentence-transformers/all-MiniLM-L6-v2")
    )

    doc = pipe.run(texts="Tu texto largo aqu√≠...")
    for ch in doc.chunks:
        print(ch.text)
```

Este sistema modular permite personalizar cada paso seg√∫n las necesidades del proyecto.


<br/>
### Limitaciones actuales

* Dependencia de modelos externos para embeddings y chunking sem√°ntico.
* Comunidad todav√≠a peque√±a.
* Riesgo de mantenimiento: el repositorio fue temporalmente cerrado por su autor por motivos legales, aunque posteriormente fue restablecido.
* Curva de aprendizaje inicial al configurar pipelines complejas.


<br/>
##  Docling: comprensi√≥n estructural profunda de documentos

> *‚ÄúFrom document chaos to structured knowledge‚Äù*
> üëâ <a href="https://github.com/docling-project/docling" title="Docling en GitHub">https://github.com/docling-project/docling</a>

### ¬øQu√© es Docling?

Desarrollada por el equipo *Deep Search* de IBM, **Docling** es una herramienta open source centrada en **convertir documentos complejos** (PDF, DOCX, PPTX, HTML, im√°genes, etc.) en una representaci√≥n estructurada lista para IA.

Su meta no es solo extraer texto, sino **entender la estructura visual y sem√°ntica** del documento: tablas, encabezados, columnas, jerarqu√≠a, im√°genes, etc.


<br/>
### Capacidades principales

* **Parsing avanzado de PDF**: detecci√≥n de columnas, encabezados y orden de lectura.
* **Extracci√≥n de tablas** con modelos espec√≠ficos como *TableFormer*.
* **OCR integrado** para documentos escaneados.
* **Representaci√≥n rica del documento**: crea objetos `DoclingDocument` con secciones, tablas, figuras y metadatos.
* **Integraci√≥n con LangChain** mediante `DoclingLoader`.
* **Soporte para Markdown, JSON o chunks personalizados.**

Ejemplo de uso con LangChain:

```python
    from langchain_community.document_loaders import DoclingLoader

    loader = DoclingLoader(file_path="documento.pdf", output_format="MARKDOWN")
    docs = loader.load()
```


<br/>
### Casos de uso

* Conversi√≥n de informes, papers y presentaciones a texto estructurado.
* Preprocesamiento de documentos para QA y RAG.
* Extracci√≥n de datos de documentos semi estructurados.
* Ingesti√≥n de datos empresariales a gran escala (PDFs, escaneos, documentos internos).


## ‚öñ Comparativa: Chonkie vs Docling

| Aspecto                      | **Chonkie**                                          | **Docling**                                               |
| ---------------------------- | ---------------------------------------------------- | --------------------------------------------------------- |
| **Prop√≥sito**                | Fragmentar texto para pipelines RAG                  | Convertir documentos complejos en texto estructurado      |
| **Nivel de entrada**         | Texto plano (ya preprocesado)                        | Formatos crudos (PDF, DOCX, im√°genes, etc.)               |
| **Conciencia de estructura** | No analiza dise√±o o layout                           | Comprende tablas, columnas, jerarqu√≠a, layout             |
| **Chunking**                 | M√∫ltiples estrategias (tokens, oraciones, sem√°ntico) | Dispone de un m√≥dulo b√°sico, pero su foco es estructural  |
| **Rendimiento**              | Muy r√°pido y ligero                                  | M√°s pesado debido al uso de modelos de visi√≥n / OCR       |
| **Integraci√≥n IA / RAG**     | Nativa con bases vectoriales y embeddings            | Compatible con LangChain y otros loaders                  |
| **Mantenimiento**            | Proyecto joven con comunidad emergente               | Respaldado por IBM, documentaci√≥n y publicaci√≥n acad√©mica |
| **Uso ideal**                | Procesar texto limpio y fragmentarlo √≥ptimamente     | Ingesta y estructuraci√≥n previa de documentos complejos   |


<br/>
##  C√≥mo combinarlas para maximizar resultados

En realidad, **Chonkie** y **Docling** no son competidores, sino aliados naturales.

Una estrategia h√≠brida ideal podr√≠a ser:

1. **Usar Docling** para convertir PDFs, DOCX o escaneos en una representaci√≥n estructurada (`DoclingDocument`).
2. **Extraer los textos** de secciones o p√°rrafos relevantes.
3. **Aplicar Chonkie** sobre esos fragmentos para optimizar el chunking (por tokens, sem√°ntico o recursivo).
4. **Indexar los chunks** resultantes en una base vectorial para b√∫squeda o recuperaci√≥n aumentada.

As√≠ obtienes lo mejor de ambos mundos: comprensi√≥n profunda de estructura documental y fragmentaci√≥n eficiente optimizada para modelos de lenguaje.


<br/>
##  Conclusi√≥n

* **Docling** es el traductor entre el caos documental y la estructura sem√°ntica.
* **Chonkie** es el afinador que transforma ese texto limpio en fragmentos √≥ptimos para IA.

Combinarlas permite construir pipelines RAG m√°s precisas, r√°pidas y robustas, especialmente cuando se trabaja con documentos complejos y multiformato.
Si quieres profundizar m√°s sobre Docling tengo este <a href="https://marcmayol.com/blog/en/docling-the-easy-way-to-use-files-with-llms/" title="Docling: la forma f√°cil de trabajar con archivos y LLMs"> art√≠culo</a> donde lo explico en detalle o tambi√©n el propio art√≠culo de <a href="https://marcmayol.com/blog/en/chonkie-the-art-of-chunking-text-intelligently/" title="Chonkie">Chonkie</a>.

>  Consejo: si est√°s construyendo tu propio sistema RAG, prueba usar Docling para ingesti√≥n y Chonkie para chunking. Tu modelo te lo agradecer√°.
